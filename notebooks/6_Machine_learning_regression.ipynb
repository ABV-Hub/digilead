{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning: regression\n",
    "\n",
    "We'll try to predict missing well logs using regression.\n",
    "\n",
    "The data are from Colorado. We've already loaded the data into a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = 'https://s3.amazonaws.com/agilegeo/geocomp/Colorado_well_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(uri, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual inspection of the data space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well = 1\n",
    "\n",
    "features = ['CAL', 'SP', 'GR', 'RES', 'NPHI', 'RHOB']\n",
    "target = 'DT'\n",
    "\n",
    "fig, axs = plt.subplots(ncols=len(features)+1, sharey=True, figsize=(8,8))\n",
    "\n",
    "for ax, feature in zip(axs, features):\n",
    "    ax.plot(df.loc[df.Well==well, feature], df.loc[df.Well==well, 'Depth'])\n",
    "    ax.set_title(feature)\n",
    "axs[-1].plot(df.loc[df.Well==well, target], df.loc[df.Well==well, 'Depth'], color='red')\n",
    "axs[-1].set_title(target)\n",
    "axs[-1].invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=len(features), figsize=(15, 3))\n",
    "\n",
    "for ax, feature in zip(axs, features):\n",
    "    ax = sns.distplot(df[feature], ax=ax)\n",
    "    ax.set_title(feature)\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a 'log<sub>10</sub> resisitivity' to deal with the usual RES distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogRes'] = np.log10(df.RES)\n",
    "df = df.loc[df.LogRes > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.LogRes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And update the `features` list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove('RES')\n",
    "features.append('LogRes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fix the gamma ray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.GR = df.GR.clip(upper=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.GR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "And the NPHI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(0 <= df.NPHI) & (df.NPHI <= 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df.NPHI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=len(features), figsize=(15, 3))\n",
    "\n",
    "for ax, feature in zip(axs, features):\n",
    "    ax = sns.distplot(df[feature], ax=ax)\n",
    "    ax.set_title(feature)\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df[df.Well == 1.0], vars=features[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many wells are in the data set\n",
    "df.Well.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.Well.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's start by training on the first five wells only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5  # We'll come back and change this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.Well <= n].copy()\n",
    "df_val = df[(df.Well >= 70) & (df.Well < 80)].copy()\n",
    "df_test = df[(df.Well >= 80) & (df.Well < 90)].copy()\n",
    "df_app = df[df.Well >= 90].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['GR', 'NPHI', 'RHOB', 'LogRes']\n",
    "target = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[features].values\n",
    "y_train = df_train[target].values\n",
    "\n",
    "X_val = df_val[features].values\n",
    "y_val = df_val[target].values\n",
    "\n",
    "X_test = df_test[features].values\n",
    "y_test = df_test[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=len(features), figsize=(15,3))\n",
    "\n",
    "for ax, feature in zip(axs, features):\n",
    "    sns.distplot(df_train[feature], ax=ax)\n",
    "    sns.distplot(df_val[feature], ax=ax)\n",
    "    sns.distplot(df_test[feature], ax=ax)\n",
    "    ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "regr = Ridge()\n",
    "regr.fit(X_train, y_train)\n",
    "df_val['DT_pred_LR'] = regr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_track(df, idx, true, pred):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    fig.set_size_inches(12,2)\n",
    "    true = df.loc[df.Well == idx, true]\n",
    "    pred = df.loc[df.Well == idx, pred]\n",
    "    depths = df.loc[df.Well == idx, 'Depth']\n",
    "    ax.plot(depths, true, 'k', lw=1.5)\n",
    "    ax.plot(depths, pred, 'r', lw=1.5)\n",
    "    ax.set_xlim(1300, 2400)\n",
    "    ax.set_ylim(40, 140)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(idx=(df_val.Well.unique().min(), df_val.Well.unique().max(), 1))\n",
    "def plot_different_wells(idx):\n",
    "    plot_track(df_val, idx, 'DT', 'DT_pred_LR')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "r2_score(df_val.DT, df_val.DT_pred_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the RMS error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(df_val.DT, df_val.DT_pred_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check error distribution\n",
    "\n",
    "In particular, we want to check that:\n",
    "\n",
    "1. The errors are normally distributed with a zero mean.\n",
    "1. The variance of the errors is not correlated with the parameters.\n",
    "\n",
    "There's some good advice about normality tests in [this article by Jason Brownlee](https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/).\n",
    "\n",
    "First we'll just use visual inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = df_val['DT_pred_LR'] - df_val['DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(residuals)\n",
    "plt.axvline(0, color='k', lw=0.5)\n",
    "plt.axvline(residuals.mean(), color='r')\n",
    "plt.grid(color='k', alpha=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normality: QQ plot\n",
    "\n",
    "A quantile-quantile plot generates an idealized distribution, in this case a Gaussian. The idealized samples are divided into quantiles, then each data point in the sample is paired with a similar member from the idealized distribution. The line `'s'` represents the standard 'normal' distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "qqplot(residuals, line='s')\n",
    "plt.axvline(0, color='k', lw=0.5)\n",
    "plt.axhline(0, color='k', lw=0.5)\n",
    "plt.grid(color='k', alpha=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normality: Shapiro&ndash;Wilk test\n",
    "\n",
    "Not convinced about this &mdash; seems like most large samples don't fit. `p` just gets very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "res_shuf = residuals.values\n",
    "np.random.shuffle(res_shuf)\n",
    "\n",
    "stat, p = shapiro(res_shuf[:500])\n",
    "print(f'Statistics = {stat:.3f}, p = {p:.3f}')\n",
    "\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('Sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homoscedasticity: visual inspection\n",
    "\n",
    "We want to check that the variance of the errors is not correlated with our parameters.\n",
    "\n",
    "If they are correlated (if the plots below show points with narrow spread at one end and wide at the other), then there are nonlinearities in the data that are not captured by the model. It could be that outliers are skewing the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=len(features), figsize=(16,4), sharey=True)\n",
    "\n",
    "for ax, feature in zip(axs, features):\n",
    "    ax.scatter(df_val[feature], residuals, s=1, alpha=0.1)\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.axhline(0, color='k', lw=0.5)\n",
    "    ax.grid(color='k', alpha=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there could be an issue in shales (low NPHI), and in rocks with low HC saturation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can makea list of the features that contributed most:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(reversed(np.array(features)[np.argsort(np.abs(regr.coef_))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,8))\n",
    "\n",
    "idx = np.arange(len(features))\n",
    "ax.bar(idx, regr.coef_, align='center')\n",
    "ax.axhline(0, color='k', lw=0.5)\n",
    "ax.set_xticks(idx)\n",
    "ax.set_xticklabels(features)\n",
    "ax.grid(color='k', alpha=0.15)\n",
    "\n",
    "plt.title('Feature importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><hr />\n",
    "\n",
    "<div>\n",
    "<img src=\"https://avatars1.githubusercontent.com/u/1692321?s=50\"><p style=\"text-align:center\">© Agile Geoscience 2019</p>\n",
    "</div></html>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geocomp",
   "language": "python",
   "name": "geocomp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
